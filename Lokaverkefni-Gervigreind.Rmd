---
title: "Lokaverkefni-Gervigreind"
author: "Ævar Ingi Jóhannesson"
date: "4/6/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, warning = F, message = F}
library(plyr); library(dplyr); library(lubridate)
library(ggplot2)
library(grid)
library(gridExtra)
library(glmnet)
library(e1071)
library(randomForest)
library(knitr)
library(gbm)
library(corrplot)
```

## Read data:

116 categorical og 14 continous. ID og Loss 

```{r}
data = read.csv("train.csv")
data = data[,2:132]
data.submit = read.csv("test.csv")
id=data.submit$id
```


## Data

```{r}
data.cont = data[,117:131]
data.small = data[,c(1:70,117:131)]
delete = names(data)[c(1,2,5,6,7,10,11,12,13,14)]
data.cat = data[,c(72:80,131)]
loss = data$loss
```

```{r}
corr = cor(data.cont)
corrplot(corr)
#Remove one of the variables: 1 or 9,   11 or 12

```

```{r}
ggplot(data=data, aes(x=cont11,y=cont12))+
  geom_point()

ggplot(data=data, aes(x=cont11,y=log(loss)))+
  geom_point()
```


```{r}
set.seed(1000)
data.cat = data[,c(80:116,131)] #73 74
n = dim(data)[1]
train = sample(n,floor(n*0.7))
data.train.cat = data.cat[train,]
data.test.cat = data.cat[-train,]

#pred.lm = predict(fit.lm, data.test.cat)
#MAE = mean(abs(data.test.cat$loss - pred.lm))
#MAE


#pred.submit




```


##Using Small data set.

```{r}
set.seed(1000)
data.small = data[,c(1:70,117:131)]
n = dim(data.small)[1]
train = sample(n,floor(n*0.75))
train.small = data.small[train,]
test.small = data.small[-train,]
n2 = dim(train.small)[1]
val = sample(n2,floor(n2*0.8))
val.small = train.small[-val,]
train.small = train.small[val,]


fit.lm <- lm(loss~.,data=data.small)

pred.lm = predict(fit.lm, test.small)
MAElinear = mean(abs(test.small$loss - pred.lm))
MAElinear




```

##Lasso

```{r}
set.seed(1000)
ytrain.small = data.matrix(train.small[,"loss"])
Xtrain.small = data.matrix(train.small[,!(colnames(train.small) %in% c("loss"))])
Xtest.small = data.matrix(test.small[,!(colnames(train.small) %in% c("loss"))])
grid = 10^seq(4, -20, length=1000)
fit.lasso = cv.glmnet(Xtrain.small,ytrain.small,alpha=1, lambda=grid, thresh=1e-12)
plot(fit.lasso)

best.model = glmnet(Xtrain.small, ytrain.small, alpha = 1)
predict(best.model, s = fit.lasso$lambda.1se, type = "coefficients")

best.lambda=fit.lasso$lambda.min
pred.lasso = predict(fit.lasso,Xtest.small,s=fit.lasso$lambda.1se)
MAELasso = mean(abs(test.small$loss - pred.lasso))
MAELasso



```


##Boosting.

```{r}
set.seed(1000)
lambd <-  seq(0.05, 0.5, by=0.05)
m <- length(lambd)
testErr <- rep(NA, m)
for (i in 1:m) {
    boostCol = gbm(loss ~ ., data = train.small,
                    distribution = "gaussian",
                    n.trees = 200, 
                    shrinkage = lambd[i])
    testPred = predict(boostCol, val.small, n.trees = 200)
    testErr[i] = mean(abs(val.small$loss - testPred))
    print(i)
}

bestLam = lambd[which.min(testErr)]

boostPlot =ggplot(data.frame(x=lambd, y=testErr), aes(x=x, y=y)) +
            xlab("Shrinkage") + 
            ylab("Test MSE") + 
            geom_point()


boostPlot
```

```{r,eval = T}
set.seed(1000)
boost.fit <- gbm(loss ~ ., data = train.small,
                 distribution = "gaussian",
                 n.trees = 1000, shrinkage =0.5 )
boost.pred <- predict(boost.fit,
                      test.small,
                      n.trees = 1000)
MAEBoost = mean(abs(test.small$loss - boost.pred))
MAEBoost
```



##SUBMIT

```{r}
pred.submit = predict(fit.lm,data.submit.cat)
Submit= data.frame(id,loss=boost.pred)
write.csv(Submit,file="Submit.csv",row.names=FALSE)
```

