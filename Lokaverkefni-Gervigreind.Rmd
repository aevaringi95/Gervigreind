---
title: "Lokaverkefni-Gervigreind"
author: "Ævar Ingi Jóhannesson"
date: "4/6/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
```

```{r, warning = F, message = F}
library(plyr); library(dplyr); library(lubridate)
library(ggplot2)
library(grid)
library(gridExtra)
library(glmnet)
library(e1071)
library(randomForest)
library(knitr)
library(gbm)
library(corrplot)
library(caret)
library(mlbench)
library(tictoc)
library(gdata)
```

## Load data:

```{r}
data = read.csv("train.csv")
data$id = NULL
data.submit = read.csv("test.csv")
id = data.submit$id
```

```{r}
#Check for NA values
dim(na.omit(data)) == dim(data)
```

```{r}
#Check distribution of response
density1 <- ggplot(data,aes(loss))+
  geom_density(fill = "palegreen2", alpha = 0.4) 

density2 <- ggplot(data,aes(log(loss)))+
  geom_density(fill = "skyblue", alpha = 0.4)

grid.arrange(density1,density2,nrow=2)
```

```{r}
skewness(data$loss)
skewness(log(data$loss))
data$loss = log(data$loss)
```

## Descriptive plots

```{r}
#Continuous variables
p1 = ggplot(data=data, aes(x=cont2,y=loss))+
      geom_point(size=0.4)+ylab("log(loss)")

p2 = ggplot(data=data, aes(x=cont3,y=loss))+
      geom_point(size=0.4)+ylab("log(loss)")

p3 = ggplot(data=data, aes(x=cont13,y=loss))+
      geom_point(size=0.4)+ylab("log(loss)")

p4 = ggplot(data=data, aes(x=cont14,y=loss))+
      geom_point(size=0.4)+ylab("log(loss)")

grid.arrange(p1,p2,p3,p4,nrow = 2)
```

```{r}
#Boxplots of categorical variables
b1 = ggplot(data=data, aes(x=cat7,y=loss))+
  geom_boxplot(outlier.size = 0.5)+ylab("log(loss)")

b2 = ggplot(data=data, aes(x=cat87,y=loss))+
  geom_boxplot(outlier.size = 0.5)+ylab("log(loss)")

b3 = ggplot(data=data, aes(x=cat89,y=loss))+
  geom_boxplot(outlier.size = 0.5)+ylab("log(loss)")

b4 = ggplot(data=data, aes(x=cat100,y=loss))+
  geom_boxplot(outlier.size = 0.5)+ylab("log(loss)")

b5 = ggplot(data=data, aes(x=cat101,y=loss))+
  geom_boxplot(outlier.size = 0.5)+ylab("log(loss)")

b6 = ggplot(data=data, aes(x=cat103,y=loss))+
  geom_boxplot(outlier.size = 0.5)+ylab("log(loss)")

b7 = ggplot(data=data, aes(x=cat104,y=loss))+
  geom_boxplot(outlier.size = 0.5)+ylab("log(loss)")

b8 = ggplot(data=data, aes(x=cat113,y=loss))+
  geom_boxplot(outlier.size = 0.5)+ylab("log(loss)")

grid.arrange(b1,b2,b3,b4,nrow = 2)
grid.arrange(b5,b6,b7,b8,nrow = 2)
```

```{r}
#Barplots of categorical variables
ggplot(data=data, aes(cat1))+
  geom_bar()
```

## Correlation

```{r}
data.cont = data[,117:131]
cormat = cor(data.cont[,-15])
corrplot(cormat, method = "circle")

#drop highly correlated variables
data$cont9 = NULL
data$cont12 = NULL
```

```{r}
data.try = data

#Run through all of the variables to see which one have categories with observations under 10.
for(i in 1:116){
  var = eval(parse(text = paste("data.try$cat",as.character(i),sep="")))
  print(i)
  print(table(var))
}

#Remove those categories.
data.try = data.try[data.try$cat75 %in% names(which(table(data.try$cat75) > 10)), ]
data.try = data.try[data.try$cat88 %in% names(which(table(data.try$cat88) > 10)), ]
data.try = data.try[data.try$cat89 %in% names(which(table(data.try$cat89) > 10)), ]
data.try = data.try[data.try$cat90 %in% names(which(table(data.try$cat90) > 10)), ]
data.try = data.try[data.try$cat92 %in% names(which(table(data.try$cat92) > 10)), ]
data.try = data.try[data.try$cat99 %in% names(which(table(data.try$cat99) > 10)), ]
data.try = data.try[data.try$cat101 %in% names(which(table(data.try$cat101) > 10)), ]
data.try = data.try[data.try$cat102 %in% names(which(table(data.try$cat102) > 10)), ]
data.try = data.try[data.try$cat103 %in% names(which(table(data.try$cat103) > 10)), ]
data.try = data.try[data.try$cat104 %in% names(which(table(data.try$cat104) > 10)), ]
data.try = data.try[data.try$cat105 %in% names(which(table(data.try$cat105) > 10)), ]
data.try = data.try[data.try$cat106 %in% names(which(table(data.try$cat106) > 10)), ]
data.try = data.try[data.try$cat107 %in% names(which(table(data.try$cat107) > 10)), ]
data.try = data.try[data.try$cat109 %in% names(which(table(data.try$cat109) > 10)), ]
data.try = data.try[data.try$cat110 %in% names(which(table(data.try$cat110) > 10)), ]
data.try = data.try[data.try$cat111 %in% names(which(table(data.try$cat111) > 10)), ]
data.try = data.try[data.try$cat113 %in% names(which(table(data.try$cat113) > 10)), ]
data.try = data.try[data.try$cat114 %in% names(which(table(data.try$cat114) > 10)), ]
data.try = data.try[data.try$cat115 %in% names(which(table(data.try$cat115) > 10)), ]
data.try = data.try[data.try$cat116 %in% names(which(table(data.try$cat116) > 10)), ]

data.try$cat75  = droplevels(data.try$cat75) ; data.try$cat88  = droplevels(data.try$cat88)
data.try$cat89  = droplevels(data.try$cat89) ; data.try$cat90  = droplevels(data.try$cat90)
data.try$cat92  = droplevels(data.try$cat92) ; data.try$cat99  = droplevels(data.try$cat99)
data.try$cat101 = droplevels(data.try$cat101); data.try$cat102 = droplevels(data.try$cat102)
data.try$cat103 = droplevels(data.try$cat103); data.try$cat104 = droplevels(data.try$cat104)
data.try$cat105 = droplevels(data.try$cat105); data.try$cat106 = droplevels(data.try$cat106)
data.try$cat107 = droplevels(data.try$cat107); data.try$cat109 = droplevels(data.try$cat109)
data.try$cat110 = droplevels(data.try$cat110); data.try$cat111 = droplevels(data.try$cat111)
data.try$cat113 = droplevels(data.try$cat113); data.try$cat114 = droplevels(data.try$cat114)
data.try$cat115 = droplevels(data.try$cat115); data.try$cat116 = droplevels(data.try$cat116)
```

```{r}
#taka út alla sem gefa NA gildi- þarf ekki að keyra
cat74 = data.try$cat74; data.try$cat74 = NULL
cat81 = data.try$cat81; data.try$cat81 = NULL
cat85 = data.try$cat85; data.try$cat85 = NULL
cat87 = data.try$cat87; data.try$cat87 = NULL
cat89 = data.try$cat89; data.try$cat89 = NULL
cat90 = data.try$cat90; data.try$cat90 = NULL
cat91 = data.try$cat91; data.try$cat91 = NULL
cat92 = data.try$cat92; data.try$cat92 = NULL
cat98 = data.try$cat98; data.try$cat98 = NULL
cat99 = data.try$cat99; data.try$cat99 = NULL
cat100 = data.try$cat100; data.try$cat100 = NULL 
cat101 = data.try$cat101; data.try$cat101 = NULL 
cat102 = data.try$cat102; data.try$cat102 = NULL
cat103 = data.try$cat103; data.try$cat103 = NULL 
cat104 = data.try$cat104; data.try$cat104 = NULL 
cat106 = data.try$cat106; data.try$cat106 = NULL
cat107 = data.try$cat107; data.try$cat107 = NULL
cat108 = data.try$cat108; data.try$cat108 = NULL
cat111 = data.try$cat111; data.try$cat111 = NULL
cat113 = data.try$cat113; data.try$cat113 = NULL
cat114 = data.try$cat114; data.try$cat114 = NULL
cat116 = data.try$cat116; data.try$cat116 = NULL
```

## Linear regression

```{r}
set.seed(5)
n = dim(data.try)[1]
train = sample(n,floor(n*0.7))
data.train = data.try[train,]
data.test = data.try[-train,]

lm.try = lm(loss~.,data.train)
pred.try = predict(lm.try,data.test)
pred.sub = predict(lm.try,data.submit) #virkar ekki
MAE.try = mean(abs(exp(data.test$loss) - exp(pred.try)))
MAE.try 

#1230.875 Með þvi að hafa allar breyturnar með.
#with cat115 (w/o highly correlated variables): 1266.915
#with 115 and 87: NA
#with 115 and 89: NA
#with 115 and 90: NA
#with 90: NA
#with 115 and highly correlated variables: 1266.86
#106: NA. 101: NA. 102: NA. 103: NA
```

## Regression algorithms.


##Lasso

```{r}
set.seed(1000)
ydata.train = data.matrix(data.train[,"loss"])
Xdata.train = data.matrix(data.train[,!(colnames(data.train) %in% c("loss"))])
Xdata.test = data.matrix(data.test[,!(colnames(data.train) %in% c("loss"))])
grid = 10^seq(4, -20, length=1000)
fit.lasso = cv.glmnet(Xdata.train,ydata.train,alpha=1, lambda=grid, thresh=1e-12)
plot(fit.lasso)


best.lambda=fit.lasso$lambda.min
pred.lasso = predict(fit.lasso,Xdata.test,s=best.lambda)
MAELasso = mean(abs(exp(data.test$loss) - exp(pred.lasso)))
MAELasso
#1275.478


#Bua til model ur coefs sem eru ekki 0.
coefs_temp <- predict(fit.lasso, s = fit.lasso$lambda.1se, type = "coefficients")
coefs_temp2 <- data.frame(name = coefs_temp@Dimnames[[1]][coefs_temp@i + 1], coefficient = coefs_temp@x)
names <- levels(coefs_temp2[,1])
names <- names[2:length(names)]
names <- c(names,"loss")
names
data.lasso = data.try[,names]
data.lasso.train = data.lasso[train,]
data.lasso.test = data.lasso[-val,]



```

##Boosting.

data með öllum breytum nema continuous 9 og 12, búið að taka út obs < 10 level. 
1227.14891 á kaggle
1228.434 í R
1225.518 minimum í cross validation
lambda = 0.45
ntree = 600

```{r}
n3 = dim(data.train)[1]
val = sample(n3,floor(0.2*n3)) 
data.val = data.train[val,]
data.train = data.train[-val,]
```

```{r}
set.seed(1000)
lambd <-  seq(0.05, 0.5, by=0.05)
ntree <- seq(200,1200,by=200)
m <- length(lambd)
l <- length(ntree)
testErr <- array(dim=c(m,l))
for (i in 1:m) {
  for(k in 1:l){
    boostCol = gbm(loss ~ ., data = data.train,
                    distribution = "gaussian",
                    n.trees = ntree[k], 
                    shrinkage = lambd[i])
    testPred = predict(boostCol, data.val, n.trees = ntree[k])
    testErr[i,k] = mean(abs(exp(data.val$loss) - exp(testPred)))
    print(i)
  }
}

which(testErr == min(testErr),arr.ind = T)

bestlam = lambd[9]
bestntree = ntree[3]
testErr
lambd
ntree
bestLam = lambd[which.min(testErr)]

boostPlot =ggplot(data.frame(x=lambd, y=testErr), aes(x=x, y=y)) +
            xlab("Shrinkage") + 
            ylab("Test MSE") + 
            geom_point()


boostPlot
```

```{r,eval = T}
set.seed(1000)
boost.fit <- gbm(loss ~ ., data = data.train,
                 distribution = "gaussian",
                 n.trees = bestntree, shrinkage =bestlam )
boost.pred <- predict(boost.fit,
                      data.test,
                      n.trees = bestntree)
boost.pred2 <- predict(boost.fit,
                      data.submit,
                      n.trees = bestntree)
MAEBoost = mean(abs(exp(data.test$loss) - exp(boost.pred)))
MAEBoost 
```


## Boosting a Lasso modelið.
1225.86
með lambda 0.45 og n.trees 600
1223.98559
með lambda 0.1 og n.trees 600 (Tuning)
1225
með lambda 0.1 og n.trees 5000.
1226
með lambda 0.1 og n.trees (600)

1225.51977
með lambda 0.09 og ntree 1000.


```{r}
n3 = dim(data.lasso.train)[1]
val = sample(n3,floor(0.2*n3)) 
data.lasso.val = data.lasso.train[val,]
data.lasso.train = data.lasso.train[-val,]
```

```{r}
set.seed(1000)
lambd <-  seq(0.01, 0.1, by=0.01)
ntree <- seq(1000,5000,by=1000)
m <- length(lambd)
l <- length(ntree)
testErr2 <- array(dim=c(m,l))
for (i in 1:m) {
  for(k in 1:l){
    boostCol = gbm(loss ~., data = data.lasso.train,
                    distribution = "gaussian",
                    n.trees = ntree[k], 
                    shrinkage = lambd[i])
    testPred = predict(boostCol, data.lasso.val, n.trees = ntree[k])
    testErr2[i,k] = mean(abs(exp(data.lasso.val$loss) - exp(testPred)))
    print(i)
  }
}
testErr2
best.lambd = lambd[2]
best.ntree = ntree[2]
```
Cross validation gaf lambda= 0.1 og ntree = 600.


```{r}
set.seed(1000)
boost.fit.small <- gbm(loss ~ ., data = data.lasso.train,
                 distribution = "gaussian",
                 n.trees = 1000, shrinkage =0.09 )
boost.pred.small <- predict(boost.fit.small,
                      data.submit,
                      n.trees = 1000)
MAEBoost.small = mean(abs(exp(data.lasso.test$loss) - exp(boost.pred.small)))
MAEBoost.small 
```



###Prufa XG boost.. hefur ekkert tekist ennþa

```{r}
library(xgboost)

train_y = data.lasso.train$loss
train_x = data.lasso.train[,names(data.lasso.train)!='loss']

test_y = data.lasso.test$loss
test_x = data.lasso.test[,names(data.lasso.test)!='loss']



dtrain = xgb.DMatrix(data = data.matrix(train_x), label = train_y)
dtest = xgb.DMatrix(data =  data.matrix(test_x), label = test_y)

# these are the datasets the rmse is evaluated for at each iteration
watchlist = list(train=dtrain, test=dtest)

# try 1 - off a set of paramaters I know work pretty well for most stuff

bst = xgb.train(data = dtrain, 
                max.depth = 6, 
                eta = 0.01, 
                nthread = 2, 
                nround = 10000, 
                eval_metric = "mae",
                watchlist = watchlist, 
                objective = "reg:linear", 
                early_stopping_rounds = 50,
                print_every_n = 500)


y_hat = predict(bst,data.matrix(data.submit))
MAEBoost.small2 = mean(abs(exp(data.lasso.val$loss) - exp(y_hat)))
MAEBoost.small2 

```

###Robust regression
EKKI FARIÐ AÐ VIRKA ..

```{r}
library(MASS)
data.lasso.train$cat100  = droplevels(data.lasso.train$cat100) ; data.lasso.train$cat101  = droplevels(data.lasso.train$cat101)
data.lasso.train$cat102  = droplevels(data.lasso.train$cat102) ; data.lasso.train$cat103  = droplevels(data.lasso.train$cat103)
data.lasso.train$cat105  = droplevels(data.lasso.train$cat105) ; data.lasso.train$cat111  = droplevels(data.lasso.train$cat111)
data.lasso.train$cat112 = droplevels(data.lasso.train$cat112); data.lasso.train$cat114 = droplevels(data.lasso.train$cat114)
data.lasso.train$cat99 = droplevels(data.lasso.train$cat99); data.lasso.train$cat98 = droplevels(data.lasso.train$cat98)
data.lasso.train$cat97 = droplevels(data.lasso.train$cat97)
data.lasso.train$cat92 = droplevels(data.lasso.train$cat92)
data.lasso.train$cat93 = droplevels(data.lasso.train$cat93)
data.lasso.train = droplevels(data.lasso.train)
rlm.try = rlm(loss~.,data=data.lasso.train)
pred.try = predict(rlm.try,data.test)
pred.sub = predict(rlm.try,data.submit) #virkar ekki
MAE.try = mean(abs(exp(data.test$loss) - exp(pred.try)))
MAE.try 


```




##SUBMIT

```{r}
pred.submit = predict(fit.lm,data.submit.cat)
Submit= data.frame(id,loss=exp(boost.pred.small))
write.csv(Submit,file="Submit.csv",row.names=FALSE)
```

